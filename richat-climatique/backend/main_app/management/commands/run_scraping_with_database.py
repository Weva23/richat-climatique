# =============================================================================
# FICHIER: run_scraping_with_database.py
# SCRIPT PRINCIPAL POUR EX√âCUTER LE SCRAPING AVEC INT√âGRATION BASE DE DONN√âES
# =============================================================================

import os
import sys
import django

# Configuration Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'funding_tracker.settings')
django.setup()

from django.core.management import call_command
from main_app.models import ScrapedProject, Project, ScrapingSession, CustomUser
from datetime import datetime

def main():
    print("üöÄ SCRAPING AVEC INT√âGRATION BASE DE DONN√âES")
    print("=" * 60)
    print(f"üïí D√©marr√© le: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    print()
    
    # 1. Afficher l'√©tat actuel de la base
    print("üìä √âTAT ACTUEL DE LA BASE DE DONN√âES:")
    print(f"   - Projets scrap√©s: {ScrapedProject.objects.count()}")
    print(f"   - Projets Django: {Project.objects.count()}")
    print(f"   - Sessions de scraping: {ScrapingSession.objects.count()}")
    print(f"   - Consultants: {CustomUser.objects.count()}")
    print()
    
    # 2. Ex√©cuter les migrations si n√©cessaire
    print("üîß V√âRIFICATION DES MIGRATIONS...")
    try:
        call_command('makemigrations', 'main_app', interactive=False)
        call_command('migrate', interactive=False)
        print("   ‚úÖ Migrations appliqu√©es")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Erreur migrations: {e}")
    print()
    
    # 3. Cr√©er un superutilisateur si n√©cessaire
    print("üë§ V√âRIFICATION UTILISATEURS...")
    if not CustomUser.objects.filter(is_superuser=True).exists():
        print("   Cr√©ation d'un superutilisateur...")
        try:
            call_command(
                'createsuperuser',
                '--username=admin',
                '--email=admin@richat-partners.com',
                '--noinput'
            )
            # D√©finir le mot de passe
            admin = CustomUser.objects.get(username='admin')
            admin.set_password('admin123')
            admin.first_name = 'Super'
            admin.last_name = 'Admin'
            admin.level = 'N4'
            admin.department = 'Administration'
            admin.save()
            print("   ‚úÖ Superutilisateur cr√©√© (admin/admin123)")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erreur cr√©ation admin: {e}")
    else:
        print("   ‚úÖ Superutilisateur existe d√©j√†")
    print()
    
    # 4. Ex√©cuter le scraping int√©gr√©
    print("üåç LANCEMENT DU SCRAPING INT√âGR√â...")
    print("   Param√®tres:")
    print("   - Sources: GEF et GCF")
    print("   - Pages GEF max: 10 (pour test rapide)")
    print("   - Mode: Avec interface (non headless)")
    print("   - Cr√©ation projets Django: Oui")
    print()
    
    try:
        # Lancer le scraping avec la nouvelle commande int√©gr√©e
        call_command(
            'integrated_scraper',
            '--source=both',
            '--max-pages=10',  # Limit√© pour le test
            '--create-projects',
            # '--headless'  # Comment√© pour voir le navigateur
        )
        print("   ‚úÖ Scraping termin√© avec succ√®s!")
        
    except Exception as e:
        print(f"   ‚ùå Erreur pendant le scraping: {e}")
        print("   üí° V√©rifiez que Chrome et chromedriver sont install√©s")
        
        # Fallback: essayer de synchroniser depuis les fichiers Excel existants
        print("\nüîÑ TENTATIVE DE SYNCHRONISATION DEPUIS FICHIERS EXCEL...")
        try:
            call_command('sync_scraped_data', '--excel-dir=scraped_data')
            print("   ‚úÖ Synchronisation depuis Excel r√©ussie!")
        except Exception as e2:
            print(f"   ‚ùå Erreur synchronisation Excel: {e2}")
    
    print()
    
    # 5. Afficher les r√©sultats
    print("üìà R√âSULTATS APR√àS SCRAPING:")
    scraped_count = ScrapedProject.objects.count()
    project_count = Project.objects.count()
    sessions_count = ScrapingSession.objects.count()
    
    print(f"   - Projets scrap√©s: {scraped_count}")
    print(f"   - Projets Django: {project_count}")
    print(f"   - Sessions: {sessions_count}")
    
    if scraped_count > 0:
        # Statistiques par source
        gef_count = ScrapedProject.objects.filter(source='GEF').count()
        gcf_count = ScrapedProject.objects.filter(source='GCF').count()
        print(f"   - GEF: {gef_count} projets")
        print(f"   - GCF: {gcf_count} projets")
        
        # Projets de haute qualit√©
        high_quality = ScrapedProject.objects.filter(data_completeness_score__gte=80).count()
        print(f"   - Haute qualit√© (‚â•80%): {high_quality} projets")
        
        # Projets pr√™ts pour conversion
        ready_for_conversion = ScrapedProject.objects.filter(
            linked_project__isnull=True,
            is_relevant_for_mauritania=True,
            data_completeness_score__gte=60
        ).count()
        print(f"   - Pr√™ts pour conversion: {ready_for_conversion} projets")
    
    print()
    
    # 6. Afficher les informations pour acc√©der √† l'application
    print("üåê ACC√àS √Ä L'APPLICATION:")
    print("   1. D√©marrer le serveur Django:")
    print("      python manage.py runserver")
    print()
    print("   2. Acc√©der √† l'interface:")
    print("      - Application: http://localhost:8000/")
    print("      - Admin Django: http://localhost:8000/admin/")
    print("      - API: http://localhost:8000/api/")
    print()
    print("   3. Connexion:")
    print("      - Admin: admin / admin123")
    print("      - API Token: Disponible via /api/auth/login/")
    print()
    
    # 7. Afficher les endpoints API utiles
    print("üì° ENDPOINTS API POUR LES DONN√âES SCRAP√âES:")
    print("   - GET /api/scraped-projects/ - Liste des projets scrap√©s")
    print("   - GET /api/scraped-projects/stats/ - Statistiques")
    print("   - GET /api/scraped-projects/ready-for-creation/ - Pr√™ts √† convertir")
    print("   - POST /api/scraped-projects/{id}/create-django-project/ - Convertir")
    print("   - GET /api/scraping-sessions/ - Sessions de scraping")
    print("   - GET /api/projects/ - Projets Django")
    print()
    
    # 8. Prochaines √©tapes
    print("üéØ PROCHAINES √âTAPES:")
    print("   1. ‚úÖ V√©rifier les donn√©es dans l'admin Django")
    print("   2. ‚úÖ Tester l'API avec les nouveaux endpoints")
    print("   3. ‚úÖ Convertir les projets scrap√©s en projets Django")
    print("   4. ‚úÖ Mettre √† jour le frontend pour afficher ces donn√©es")
    print("   5. ‚úÖ Programmer des t√¢ches de scraping automatiques")
    print()
    
    print("üéâ CONFIGURATION TERMIN√âE!")
    print("   Les donn√©es scrap√©es sont maintenant int√©gr√©es √† votre application!")

def test_api_data():
    """Teste que les donn√©es sont bien accessibles via l'API"""
    print("\nüß™ TEST D'ACC√àS AUX DONN√âES...")
    
    # Test des mod√®les
    try:
        scraped = ScrapedProject.objects.first()
        if scraped:
            print(f"   ‚úÖ Premier projet scrap√©: {scraped.title[:50]}...")
            print(f"      - Source: {scraped.source}")
            print(f"      - Score: {scraped.data_completeness_score}%")
            print(f"      - Organisation: {scraped.organization}")
        
        project = Project.objects.first()
        if project:
            print(f"   ‚úÖ Premier projet Django: {project.name[:50]}...")
            print(f"      - Type: {project.type_project}")
            print(f"      - Statut: {project.status}")
            print(f"      - Score: {project.score_viabilite}")
        
        print("   ‚úÖ Acc√®s aux donn√©es OK")
        
    except Exception as e:
        print(f"   ‚ùå Erreur acc√®s donn√©es: {e}")

def create_test_data():
    """Cr√©e quelques donn√©es de test si le scraping √©choue"""
    print("\nüß™ CR√âATION DE DONN√âES DE TEST...")
    
    if ScrapedProject.objects.count() == 0:
        print("   Cr√©ation de projets scrap√©s de test...")
        
        # Donn√©es de test GEF
        ScrapedProject.objects.create(
            title="Projet Test GEF - Adaptation climatique Mauritanie",
            source="GEF",
            source_id="GEF-TEST-001",
            description="Projet test pour l'adaptation au changement climatique en Mauritanie",
            organization="Minist√®re de l'Environnement",
            project_type="Climate Change Adaptation",
            total_funding="USD 2,500,000",
            funding_amount=2500000,
            country="Mauritania",
            focal_areas="Climate Change",
            data_completeness_score=85,
            scraping_source="test_data"
        )
        
        # Donn√©es de test GCF
        ScrapedProject.objects.create(
            title="Projet Test GCF - √ânergies renouvelables",
            source="GCF",
            source_id="GCF-TEST-001",
            description="Projet test pour le d√©veloppement des √©nergies renouvelables",
            organization="Agence de D√©veloppement Durable",
            project_type="Funding Proposal",
            total_funding="USD 5,000,000",
            funding_amount=5000000,
            country="Mauritania",
            data_completeness_score=90,
            scraping_source="test_data"
        )
        
        print("   ‚úÖ 2 projets de test cr√©√©s")
    else:
        print("   ‚úÖ Des donn√©es existent d√©j√†")

if __name__ == "__main__":
    try:
        main()
        test_api_data()
        
        # Si pas de donn√©es, cr√©er des donn√©es de test
        if ScrapedProject.objects.count() == 0:
            create_test_data()
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        print(f"\n‚ùå Erreur g√©n√©rale: {e}")
        print("\nüí° D√âPANNAGE:")
        print("   1. V√©rifiez que Django est configur√©")
        print("   2. V√©rifiez les variables d'environnement")
        print("   3. V√©rifiez que la base de donn√©es est accessible")
        print("   4. Lancez: python manage.py check")


# =============================================================================
# SCRIPT S√âPAR√â POUR JUSTE LANCER LE SCRAPING
# =============================================================================

def run_quick_scraping():
    """Lance juste le scraping sans toute la configuration"""
    print("üöÄ SCRAPING RAPIDE")
    print("=" * 30)
    
    try:
        call_command(
            'integrated_scraper',
            '--source=gcf',  # Juste GCF plus rapide
            '--max-details=20',  # Limit√©
            '--create-projects',
            '--headless'
        )
        print("‚úÖ Scraping rapide termin√©!")
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")

# =============================================================================
# UTILITAIRES POUR V√âRIFIER L'INT√âGRATION
# =============================================================================

def check_integration():
    """V√©rifie que l'int√©gration fonctionne correctement"""
    print("üîç V√âRIFICATION DE L'INT√âGRATION")
    print("=" * 40)
    
    checks = []
    
    # 1. V√©rifier les mod√®les
    try:
        from main_app.models import ScrapedProject, Project, ScrapingSession
        checks.append(("‚úÖ", "Mod√®les import√©s"))
    except Exception as e:
        checks.append(("‚ùå", f"Erreur mod√®les: {e}"))
    
    # 2. V√©rifier la base de donn√©es
    try:
        count = ScrapedProject.objects.count()
        checks.append(("‚úÖ", f"Base accessible ({count} projets scrap√©s)"))
    except Exception as e:
        checks.append(("‚ùå", f"Erreur base: {e}"))
    
    # 3. V√©rifier les serializers
    try:
        from main_app.serializers import ScrapedProjectSerializer
        checks.append(("‚úÖ", "Serializers OK"))
    except Exception as e:
        checks.append(("‚ùå", f"Erreur serializers: {e}"))
    
    # 4. V√©rifier les vues
    try:
        from main_app.views import ScrapedProjectViewSet
        checks.append(("‚úÖ", "Vues API OK"))
    except Exception as e:
        checks.append(("‚ùå", f"Erreur vues: {e}"))
    
    # Afficher les r√©sultats
    for status, message in checks:
        print(f"   {status} {message}")
    
    # Recommandations
    print("\nüí° RECOMMANDATIONS:")
    if all(check[0] == "‚úÖ" for check in checks):
        print("   üéâ Tout est en ordre! Vous pouvez lancer le scraping.")
    else:
        print("   ‚ö†Ô∏è  Certains probl√®mes d√©tect√©s. V√©rifiez:")
        print("      1. Les migrations Django: python manage.py migrate")
        print("      2. Les imports dans settings.py")
        print("      3. La configuration de la base de donn√©es")

def show_api_examples():
    """Affiche des exemples d'utilisation de l'API"""
    print("\nüìö EXEMPLES D'UTILISATION DE L'API")
    print("=" * 40)
    
    examples = [
        {
            "title": "Lister tous les projets scrap√©s",
            "method": "GET",
            "url": "/api/scraped-projects/",
            "description": "R√©cup√®re tous les projets scrap√©s avec pagination"
        },
        {
            "title": "Statistiques des donn√©es scrap√©es",
            "method": "GET", 
            "url": "/api/scraped-projects/stats/",
            "description": "Statistiques globales (total, par source, etc.)"
        },
        {
            "title": "Projets pr√™ts √† √™tre convertis",
            "method": "GET",
            "url": "/api/scraped-projects/ready-for-creation/",
            "description": "Projets avec donn√©es suffisantes pour conversion"
        },
        {
            "title": "Convertir un projet scrap√©",
            "method": "POST",
            "url": "/api/scraped-projects/{id}/create-django-project/",
            "description": "Cr√©e un projet Django depuis un projet scrap√©"
        },
        {
            "title": "Sessions de scraping",
            "method": "GET",
            "url": "/api/scraping-sessions/",
            "description": "Historique des sessions de scraping"
        },
        {
            "title": "Filtrer par source",
            "method": "GET",
            "url": "/api/scraped-projects/?source=GEF",
            "description": "Filtrer les projets par source (GEF/GCF)"
        },
        {
            "title": "Recherche textuelle",
            "method": "GET",
            "url": "/api/scraped-projects/?search=climat",
            "description": "Rechercher dans titre, organisation, description"
        }
    ]
    
    for example in examples:
        print(f"\nüîπ {example['title']}")
        print(f"   {example['method']} {example['url']}")
        print(f"   ‚Üí {example['description']}")

def show_frontend_integration():
    """Montre comment int√©grer dans le frontend React"""
    print("\n‚öõÔ∏è  INT√âGRATION FRONTEND")
    print("=" * 30)
    
    print("üìÅ Nouveaux fichiers √† cr√©er:")
    print("   - src/hooks/useScrapedProjects.ts")
    print("   - src/services/scrapedProjectService.ts")
    print("   - src/pages/ScrapedProjects.tsx")
    print("   - src/components/ScrapedProjectCard.tsx")
    
    print("\nüîß Hooks React sugg√©r√©s:")
    hooks_example = """
// src/hooks/useScrapedProjects.ts
import { useQuery } from '@tanstack/react-query';
import { scrapedProjectService } from '../services/scrapedProjectService';

export const useScrapedProjects = (filters = {}) => {
  return useQuery({
    queryKey: ['scraped-projects', filters],
    queryFn: () => scrapedProjectService.getScrapedProjects(filters)
  });
};

export const useScrapedProjectStats = () => {
  return useQuery({
    queryKey: ['scraped-projects-stats'],
    queryFn: () => scrapedProjectService.getStats()
  });
};
"""
    print(hooks_example)
    
    print("üéõÔ∏è  Composant sugg√©r√©:")
    component_example = """
// src/pages/ScrapedProjects.tsx
const ScrapedProjects = () => {
  const { data: projects, isLoading } = useScrapedProjects();
  const { data: stats } = useScrapedProjectStats();
  
  return (
    <div>
      <h1>Projets Scrap√©s ({stats?.total_scraped || 0})</h1>
      <div className="stats-grid">
        <StatCard title="GEF" value={stats?.by_source?.GEF || 0} />
        <StatCard title="GCF" value={stats?.by_source?.GCF || 0} />
        <StatCard title="Pr√™ts" value={stats?.ready_projects || 0} />
      </div>
      <ScrapedProjectsList projects={projects} />
    </div>
  );
};
"""
    print(component_example)

# =============================================================================
# MENU INTERACTIF
# =============================================================================

def interactive_menu():
    """Menu interactif pour choisir les actions"""
    while True:
        print("\n" + "="*50)
        print("üöÄ MENU SCRAPING & INT√âGRATION")
        print("="*50)
        print("1. üîß V√©rifier l'int√©gration")
        print("2. üåç Lancer scraping complet (GEF + GCF)")
        print("3. ‚ö° Scraping rapide (GCF seulement)")
        print("4. üìä Afficher statistiques actuelles")
        print("5. üîÑ Convertir projets scrap√©s en projets Django")
        print("6. üìö Voir exemples API")
        print("7. ‚öõÔ∏è  Guide int√©gration frontend")
        print("8. üß™ Cr√©er donn√©es de test")
        print("9. ‚ùå Quitter")
        print()
        
        try:
            choice = input("Choisissez une option (1-9): ").strip()
            
            if choice == "1":
                check_integration()
            
            elif choice == "2":
                print("\nüåç Lancement scraping complet...")
                main()
            
            elif choice == "3":
                print("\n‚ö° Scraping rapide...")
                run_quick_scraping()
            
            elif choice == "4":
                print("\nüìä Statistiques actuelles:")
                print(f"   - Projets scrap√©s: {ScrapedProject.objects.count()}")
                print(f"   - Projets Django: {Project.objects.count()}")
                print(f"   - Sessions: {ScrapingSession.objects.count()}")
                
                if ScrapedProject.objects.exists():
                    gef_count = ScrapedProject.objects.filter(source='GEF').count()
                    gcf_count = ScrapedProject.objects.filter(source='GCF').count()
                    print(f"   - GEF: {gef_count}")
                    print(f"   - GCF: {gcf_count}")
                    
                    ready = ScrapedProject.objects.filter(
                        linked_project__isnull=True,
                        data_completeness_score__gte=60
                    ).count()
                    print(f"   - Pr√™ts conversion: {ready}")
            
            elif choice == "5":
                print("\nüîÑ Conversion des projets scrap√©s...")
                try:
                    call_command('migrate_scraped_data', '--min-score=60')
                    print("‚úÖ Conversion termin√©e!")
                except Exception as e:
                    print(f"‚ùå Erreur: {e}")
            
            elif choice == "6":
                show_api_examples()
            
            elif choice == "7":
                show_frontend_integration()
            
            elif choice == "8":
                create_test_data()
            
            elif choice == "9":
                print("üëã Au revoir!")
                break
            
            else:
                print("‚ùå Option invalide. Choisissez entre 1 et 9.")
        
        except KeyboardInterrupt:
            print("\nüëã Au revoir!")
            break
        except Exception as e:
            print(f"‚ùå Erreur: {e}")


# =============================================================================
# POINT D'ENTR√âE PRINCIPAL
# =============================================================================

if __name__ == "__main__":
    import sys
    
    # Si argument en ligne de commande
    if len(sys.argv) > 1:
        action = sys.argv[1].lower()
        
        if action == "check":
            check_integration()
        elif action == "scrape":
            main()
        elif action == "quick":
            run_quick_scraping()
        elif action == "test":
            create_test_data()
        elif action == "convert":
            call_command('migrate_scraped_data', '--min-score=60')
        else:
            print(f"‚ùå Action inconnue: {action}")
            print("Actions disponibles: check, scrape, quick, test, convert")
    else:
        # Menu interactif par d√©faut
        interactive_menu()


# =============================================================================
# INSTRUCTIONS D'UTILISATION
# =============================================================================

"""
üöÄ COMMENT UTILISER CE SCRIPT:

1. PR√âPARATION:
   - Assurez-vous que Django est configur√©
   - Installez les d√©pendances: pip install -r requirements.txt
   - Appliquez les migrations: python manage.py migrate

2. EX√âCUTION:
   
   A. Menu interactif (recommand√©):
      python run_scraping_with_database.py
   
   B. Actions directes:
      python run_scraping_with_database.py check    # V√©rifier l'int√©gration
      python run_scraping_with_database.py scrape   # Scraping complet
      python run_scraping_with_database.py quick    # Scraping rapide
      python run_scraping_with_database.py test     # Cr√©er donn√©es test
      python run_scraping_with_database.py convert  # Convertir projets

3. APR√àS LE SCRAPING:
   - D√©marrez le serveur: python manage.py runserver
   - V√©rifiez l'admin: http://localhost:8000/admin/
   - Testez l'API: http://localhost:8000/api/scraped-projects/
   - Int√©grez dans votre frontend React

4. SURVEILLANCE:
   - Les sessions de scraping sont track√©es dans ScrapingSession
   - Les erreurs sont logg√©es
   - Les statistiques sont disponibles via l'API

5. MAINTENANCE:
   - Programmez des t√¢ches automatiques avec Django-cron
   - Nettoyez les doublons r√©guli√®rement
   - Surveillez la qualit√© des donn√©es (scores de compl√©tude)

üéØ OBJECTIF:
   Vos 94 projets scrap√©s seront maintenant visibles dans votre application
   et pourront √™tre convertis en projets Django pour workflow complet!
"""